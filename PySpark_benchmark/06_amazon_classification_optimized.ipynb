{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized PySpark ML pipeline for classification (Amazon Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PYSPARK OPTIMIZED BENCHMARK - AMAZON REVIEWS (Manual Features)\n",
      "======================================================================\n",
      "Optimizations: Kryo Serializer, Explicit Schema, Caching\n",
      "\n",
      "Initializing Spark Session (with optimizations)...\n",
      "   Initialization time: 0.52s\n",
      "\n",
      "Loading data with explicit schema from ../datasets/Amazon Reviews/*.tsv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loaded 12106558 records in 7.37s\n",
      "\n",
      "Extracting features & caching...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature extraction & caching time: 42.04s\n",
      "   Training size: 8473236, Test size: 3633322\n",
      "\n",
      "Training and evaluating models...\n",
      "\n",
      "   Training: Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      [Logistic Regression]\n",
      "      Accuracy:   0.7725\n",
      "      F1 Score:   0.7359\n",
      "      Time:       15.20s\n",
      "      Throughput: 557,625 records/s\n",
      "\n",
      "   Training: Decision Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      [Decision Tree]\n",
      "      Accuracy:   0.7839\n",
      "      F1 Score:   0.7561\n",
      "      Time:       20.35s\n",
      "      Throughput: 416,466 records/s\n",
      "\n",
      "Cleaning up...\n",
      "   Cleanup time: 0.00s\n",
      "\n",
      "======================================================================\n",
      "TIMING BREAKDOWN\n",
      "======================================================================\n",
      "Spark Initialization:       0.52s\n",
      "Data Loading:               7.37s\n",
      "Feature Extract+Cache:     42.04s\n",
      "Training (both models):    35.55s\n",
      "Cleanup:                    0.00s\n",
      "----------------------------------------------------------------------\n",
      "TOTAL END-TO-END TIME:     85.51s\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "--- Summary of OPTIMIZED Benchmark (Manual Features) ---\n",
      "======================================================================\n",
      "Model                | Acc    | F1     | Time (s)  | Throughput (rec/s)  \n",
      "----------------------------------------------------------------------\n",
      "Logistic Regression  | 0.7725 | 0.7359 | 15.20s | 557,625\n",
      "Decision Tree        | 0.7839 | 0.7561 | 20.35s | 416,466\n",
      "\n",
      "======================================================================\n",
      "COMPARISON METRICS\n",
      "======================================================================\n",
      "Total Job Time:         85.51s\n",
      "Training Records:       8473236\n",
      "Test Records:           3633322\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, expr, udf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark import StorageLevel\n",
    "import time\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "DATA_PATH = \"../datasets/Amazon Reviews/*.tsv\" \n",
    "MAX_LR_ITERATIONS = 100\n",
    "\n",
    "# ============================================================\n",
    "# STOP ANY EXISTING SPARK SESSION\n",
    "# ============================================================\n",
    "try:\n",
    "    spark_temp = SparkSession.getActiveSession()\n",
    "    if spark_temp:\n",
    "        print(\"Stopping existing Spark session...\")\n",
    "        spark_temp.stop()\n",
    "        import time as time_sleep\n",
    "        time_sleep.sleep(2)  # Give it time to fully stop\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ============================================================\n",
    "# START TOTAL BENCHMARK TIMING\n",
    "# ============================================================\n",
    "TOTAL_BENCHMARK_START = time.time()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PYSPARK OPTIMIZED BENCHMARK - AMAZON REVIEWS (Manual Features)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Optimizations: Kryo Serializer, Explicit Schema, Caching\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# INITIALIZE SPARK SESSION (OPTIMIZED)\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nInitializing Spark Session (with optimizations)...\")\n",
    "init_start = time.time()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AmazonReviewsOptimizedManual\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max.mb\", \"512\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"24\") \\\n",
    "    .config(\"spark.default.parallelism\", \"24\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "init_time = time.time() - init_start\n",
    "print(f\"   Initialization time: {init_time:.2f}s\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# DEFINE SCHEMA AND FEATURE EXTRACTION\n",
    "# ------------------------------------------------------------\n",
    "schema = StructType([\n",
    "    StructField(\"marketplace\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"review_id\", StringType(), True),\n",
    "    StructField(\"product_id\", StringType(), True),\n",
    "    StructField(\"product_parent\", StringType(), True),\n",
    "    StructField(\"product_title\", StringType(), True),\n",
    "    StructField(\"product_category\", StringType(), True),\n",
    "    StructField(\"star_rating\", StringType(), True),\n",
    "    StructField(\"helpful_votes\", StringType(), True),\n",
    "    StructField(\"total_votes\", StringType(), True),\n",
    "    StructField(\"vine\", StringType(), True),\n",
    "    StructField(\"verified_purchase\", StringType(), True),\n",
    "    StructField(\"review_headline\", StringType(), True),\n",
    "    StructField(\"review_body\", StringType(), True),\n",
    "    StructField(\"review_date\", StringType(), True)\n",
    "])\n",
    "\n",
    "def extract_features_python(text):\n",
    "    if text is None:\n",
    "        return Vectors.dense([0.0] * 10)\n",
    "        \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    positive_words = ['great', 'good', 'excellent', 'love', 'perfect', 'best', 'amazing', 'fantastic', 'wonderful', 'awesome']\n",
    "    negative_words = ['bad', 'terrible', 'worst', 'hate', 'awful', 'horrible', 'poor', 'disappointing', 'useless', 'waste']\n",
    "    \n",
    "    features = [\n",
    "        float(len(text)),\n",
    "        float(len(text.split())),\n",
    "        float(text.count('!')),\n",
    "        float(text.count('?')),\n",
    "        float(sum(text.count(w) for w in positive_words)),\n",
    "        float(sum(text.count(w) for w in negative_words)),\n",
    "        float(text.count('not')),\n",
    "        float(1.0 if 'recommend' in text else 0.0),\n",
    "        float(1.0 if 'return' in text else 0.0),\n",
    "        float(1.0 if 'money back' in text else 0.0),\n",
    "    ]\n",
    "    return Vectors.dense(features)\n",
    "\n",
    "extract_features_udf = udf(extract_features_python, VectorUDT())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# LOAD DATA WITH EXPLICIT SCHEMA\n",
    "# ------------------------------------------------------------\n",
    "print(f\"\\nLoading data with explicit schema from {DATA_PATH}...\")\n",
    "load_start = time.time()\n",
    "\n",
    "df = spark.read.csv(DATA_PATH, header=True, schema=schema, sep=\"\\t\")\n",
    "\n",
    "# Clean & Select\n",
    "data = df.select(\n",
    "    expr(\"try_cast(star_rating as int) as star_rating\"), \n",
    "    col(\"review_body\")\n",
    ").dropna()\n",
    "\n",
    "# Binary Label\n",
    "data = data.withColumn(\"label\", when(col(\"star_rating\") > 3, 1.0).otherwise(0.0))\n",
    "\n",
    "total_records = data.count()\n",
    "load_time = time.time() - load_start\n",
    "\n",
    "print(f\"   Loaded {total_records} records in {load_time:.2f}s\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# EXTRACT FEATURES AND CACHE\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nExtracting features & caching...\")\n",
    "prep_start = time.time()\n",
    "\n",
    "featurized_data = data.withColumn(\"features\", extract_features_udf(col(\"review_body\"))) \\\n",
    "                      .select(\"features\", \"label\")\n",
    "\n",
    "# OPTIMIZATION: Persist with Memory+Disk\n",
    "featurized_data.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "# Split Data\n",
    "train_data, test_data = featurized_data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Cache test data as well\n",
    "test_data.cache()\n",
    "\n",
    "# Force materialization\n",
    "train_count = train_data.count()\n",
    "test_count = test_data.count()\n",
    "\n",
    "prep_time = time.time() - prep_start\n",
    "\n",
    "print(f\"   Feature extraction & caching time: {prep_time:.2f}s\")\n",
    "print(f\"   Training size: {train_count}, Test size: {test_count}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# TRAIN AND EVALUATE MODELS\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nTraining and evaluating models...\")\n",
    "\n",
    "evaluator_acc = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "def train_and_evaluate(model, name, total_count):\n",
    "    print(f\"\\n   Training: {name}...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    # Fit (reads from cache)\n",
    "    model_fit = model.fit(train_data)\n",
    "    predictions = model_fit.transform(test_data)\n",
    "    \n",
    "    # Force execution\n",
    "    predictions.cache()\n",
    "    num_predictions = predictions.count()\n",
    "    \n",
    "    accuracy = evaluator_acc.evaluate(predictions)\n",
    "    f1 = evaluator_f1.evaluate(predictions)\n",
    "    \n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    throughput = total_count / time_taken if time_taken > 0 else 0\n",
    "    \n",
    "    print(f\"      [{name}]\")\n",
    "    print(f\"      Accuracy:   {accuracy:.4f}\")\n",
    "    print(f\"      F1 Score:   {f1:.4f}\")\n",
    "    print(f\"      Time:       {time_taken:.2f}s\")\n",
    "    print(f\"      Throughput: {throughput:,.0f} records/s\")\n",
    "    \n",
    "    predictions.unpersist()\n",
    "    return accuracy, f1, time_taken, throughput\n",
    "\n",
    "results = []\n",
    "training_start = time.time()\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(maxIter=MAX_LR_ITERATIONS, featuresCol=\"features\", labelCol=\"label\")\n",
    "lr_acc, lr_f1, lr_time, lr_tput = train_and_evaluate(lr_model, \"Logistic Regression\", train_count)\n",
    "results.append({\"Model\": \"Logistic Regression\", \"Accuracy\": lr_acc, \"F1 Score\": lr_f1, \"Time\": lr_time, \"Throughput\": lr_tput})\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\", maxDepth=5)\n",
    "dt_acc, dt_f1, dt_time, dt_tput = train_and_evaluate(dt_model, \"Decision Tree\", train_count)\n",
    "results.append({\"Model\": \"Decision Tree\", \"Accuracy\": dt_acc, \"F1 Score\": dt_f1, \"Time\": dt_time, \"Throughput\": dt_tput})\n",
    "\n",
    "training_time = time.time() - training_start\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CLEANUP\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nCleaning up...\")\n",
    "cleanup_start = time.time()\n",
    "\n",
    "featurized_data.unpersist()\n",
    "test_data.unpersist()\n",
    "\n",
    "cleanup_time = time.time() - cleanup_start\n",
    "print(f\"   Cleanup time: {cleanup_time:.2f}s\")\n",
    "\n",
    "# ============================================================\n",
    "# END TOTAL BENCHMARK TIMING\n",
    "# ============================================================\n",
    "TOTAL_BENCHMARK_END = time.time()\n",
    "TOTAL_TIME = TOTAL_BENCHMARK_END - TOTAL_BENCHMARK_START\n",
    "\n",
    "# ============================================================\n",
    "# RESULTS SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TIMING BREAKDOWN\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Spark Initialization:   {init_time:>8.2f}s\")\n",
    "print(f\"Data Loading:           {load_time:>8.2f}s\")\n",
    "print(f\"Feature Extract+Cache:  {prep_time:>8.2f}s\")\n",
    "print(f\"Training (both models): {training_time:>8.2f}s\")\n",
    "print(f\"Cleanup:                {cleanup_time:>8.2f}s\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"TOTAL END-TO-END TIME:  {TOTAL_TIME:>8.2f}s\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"--- Summary of OPTIMIZED Benchmark (Manual Features) ---\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Model':<20} | {'Acc':<6} | {'F1':<6} | {'Time (s)':<9} | {'Throughput (rec/s)':<20}\")\n",
    "print(\"-\" * 70)\n",
    "for res in results:\n",
    "    print(f\"{res['Model']:<20} | {res['Accuracy']:.4f} | {res['F1 Score']:.4f} | {res['Time']:.2f}s | {res['Throughput']:,.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPARISON METRICS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total Job Time:         {TOTAL_TIME:.2f}s\")\n",
    "print(f\"Training Records:       {train_count}\")\n",
    "print(f\"Test Records:           {test_count}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
